# snakejob -j 100 --use-conda --keep-going --notemp -np
# snakemake --forceall --rulegraph | dot -Tpdf > docs/dag.pdf

# Directory where input imputed filesets and outputs are.
# No trailing / is required.
directory_in: HRC_impute/
directory_out: output/

SAMPLES:
  -
    COHORT: "COHORT_NAME"
    JOB:
      id: "job-20210518-083345-127"
      pwd: "5vZMb8lF\\|TdqSH"


outputs: # Comment out any line with outputs you don't want
  - stat_report # A report of imputation quality
  - vcf_bycohort # Bgzipped VCF files for each cohort
  - vcf_merged # A bgzipped VCF with all cohorts
  # - bgen_bycohort # Binary oxford filesets for each cohort
  # - bgen_merged # A binary oxford fileset with all cohorts
  - plink_bycohort # Binary plink filesets for each cohort
  - plink_merged # A binary plink fileset with all cohorts

# Select chromosomes you want to analyse and merge
#  separate ranges with ":" and listed chromosomes
#  with ","
#  You can put both in the same string.
chroms: "1:22"

# QC Parameters for filtering and analysis
qc:
  # MAF Cutoff between common and rare
  maf: 0.005
  # Rsq to use with common variants
  rsq: 0.3
  # Rsq to use with rare variants (set to NA to use rsq as hard cutoff)
  rsq2: NA
  # Number of SNPs of each type (Imputed, Typed) to sample for figures
  sampsize: 100000


# filename of samples to include
include_samp:

# filename of samples to exclude
exclude_samp:

# include_samp accepts a space/tab-delimited text file with
# vcf IDs in the first column and optional sex in the
# second column, and removes all unlisted samples
# from the current analysis. exclude_samp does the same
# for all listed samples.

# filename of sample renaming mapping file:
rename:
#  automap:
