'''Snakefile for MIS post-imputation QC'''

from getpass import getuser
import pandas as pd
import os
import socket
import re
import glob
import shutil


RWD = os.getcwd()

configfile: "config/config.yaml"

zipped = 'SAMPLES' in config and type(config['SAMPLES']) is dict

BPLINK = ["bed", "bim", "fam"]

# --- Process chromosomes config ---


def parse_chrom(chrs):
    clist = [x.split(":") for x in chrs.split(",")]
    parsed = []
    for chrs in clist:
        if len(chrs) == 2:
            chrs = [str(c) for c in range(int(chrs[0]), int(chrs[1]) + 1)]
        elif len(chrs) != 1:
            raise ValueError("Invalid chromosome list.")
        parsed += chrs
    return parsed


if 'chrom' not in config:
    CHROM = parse_chrom('1:22')
else:
    CHROM = parse_chrom(config['chroms'])

# --- Process keep and remove ---


def build_sampfilt_vcf(config):
    def filtstr(x):
        if not (x in config and config[x] and config[x] is not None):
            return None
        elif os.path.isfile(config[x]):
            paramstr = '' if x == 'include_samp' else '^'
            return '{}{}'.format(paramstr, os.path.normpath(config[x]))
        else:
            filt = 'inclusion' if x == 'include_samp' else 'exclusion'
            raise Exception("Invalid {} list: {}.".format(filt, config[x]))
    x = [filtstr(x) for x in ['include_samp', 'exclude_samp']]
    x = [i for i in x if i is not None]
    if len(x) > 1:
        raise Exception('Cannot have both sample removal and exclusion.')
    return 'bcftools view --samples-file ' + x[0] if x else ''


sampfilt = build_sampfilt_vcf(config)

# --- Process input files from config ---


def build_samp(in_path, samples=None):
    basename = lambda x: os.path.basename(x)
    p = [directory for directory, y, files in os.walk(in_path)
         if any(".zip" in f for f in files)]
    if len(p) == 0:
        p = [directory for directory,y,files in os.walk(in_path)
             if any("info.gz" in f for f in files)]
    if samples is not None:
        if not p:
            return samples
        return [basename(x) for x in p if basename(x) in samples]
    return [basename(x) for x in p]


INPATH = os.path.normpath(config["directory_in"])    #  normalize input dir
OUTPATH = os.path.normpath(config["directory_out"])  #  normalize out dir

if "SAMPLES" in config:
    COHORT = build_samp(INPATH, [*config["SAMPLES"]])
elif "COHORT" in config:
    COHORT = build_samp(INPATH, [*config["COHORT"]])
else:
    COHORT = build_samp(INPATH)

# --- Done processing ---

fixheaders = config['fixheaders'] if 'fixheaders' in config else True


def flatten(nested):
    flat = []
    for el in nested:
        if not isinstance(el, list):
            flat.append(el)
        else:
            flat += flatten(el)
    return flat


# Change filtering based on presence of rsq2
qualfilt = "(R2 >= {R2} && MAF >= {MAF})".format(
    R2=config["qc"]["rsq"], MAF=config["qc"]["maf"])
if config["qc"]["rsq2"] and config["qc"]["rsq2"] != 'NA':
    qualfilt += " || (R2 >= {R2} && MAF < {MAF})".format(
        R2=config["qc"]["rsq2"], MAF=config["qc"]["maf"])

outs = dict(
    stat_report="{impute_dir}/stats/{cohort}_impStats.html",
    vcf_bycohort="{impute_dir}/data/{cohort}_chrall_filtered.vcf.gz",
    vcf_merged="{impute_dir}/data/all_chrall_filtered.vcf.gz",
    bgen_bycohort="{impute_dir}/data/{cohort}_chrall_filtered.bgen",
    bgen_merged="{impute_dir}/data/merged/merged_chrall_filtered.bgen",
    plink_bycohort="{impute_dir}/data/{cohort}_chrall_filtered.{ext}",
    plink_merged="{impute_dir}/data/all_chrall_filtered.{ext}")


def expand_outs(out):
    return expand(out, cohort=COHORT, ext=BPLINK, impute_dir=OUTPATH)


outputs = flatten([expand_outs(outs[x]) for x in config["outputs"]])

wildcard_constraints:
    cohort = "|".join(COHORT),
    chrom = "|".join(CHROM)

rule all:
    input: outputs

if zipped:
    rule unzip:
        input: "{cohort}/chr_{chrom}.zip"
        output:
            vcf = "{impute_dir}/input/{cohort}/chr{chrom}.dose.vcf.gz",
            info = "{impute_dir}/input/{cohort}/chr{chrom}.info.gz"
        params:
            passwd = lambda wildcards: config['SAMPLES'][wildcards.cohort]['pwd'],
            odir = "{impute_dir}/input/{cohort}",
            INPATH = INPATH
        conda: 'envs/p7z.yaml'
        threads: 4
        resources:
            mem_mb = 4000,
            time_min = 5
        shell:
            r'''
            7za e {input} -p{params.passwd} -o{params.odir}
            for FILE in chunks-excluded.txt snps-excluded.txt typed-only.txt chr_{{1..22}}.log; do
              INFILE="{params.INPATH}/{wildcards.cohort}/$FILE"
              OUTFILE="{params.odir}/$FILE"
              if test -f "$INFILE"; then
                echo copying $INFILE to $OUTFILE
                cp $INFILE $OUTFILE
              fi
            done
            '''


def stats_input(wildcards):
    if zipped:
        return expand("{{impute_dir}}/input/{{cohort}}/chr{chrom}.info.gz",
            chrom=CHROM)
    else:
        return expand(INPATH + "/{{cohort}}/chr{chrom}.info.gz",
            chrom=CHROM)


rule stats:
    input:
        info = stats_input
    output:
        outfile = "{impute_dir}/stats/{cohort}_impStats.html"
    params:
        rwd = RWD,
        path = "{impute_dir}/input/{cohort}/" if zipped else INPATH + "/{cohort}/",
        chrom = CHROM,
        cohort = "{cohort}",
        maf = config["qc"]["maf"],
        rsq = config["qc"]["rsq"],
        rsq2 = config["qc"]["rsq2"],
        sampsize = config["qc"]["sampsize"],
        out = "{cohort}_impStats.html",
        output_dir = "{impute_dir}/stats",
        reading = "P"
    conda: "envs/r_stats.yaml"
    threads: 22
    resources:
        mem_mb = 24000,
        walltime = '8:00'
    script: "scripts/Post_imputation.Rmd"

# Sample filtering rules
startfile = "{impute_dir}/input/{cohort}/chr{chrom}.dose.vcf.gz" if zipped else INPATH + "/{cohort}/chr{chrom}.dose.vcf.gz"

rule indexinitial:
    input: startfile
    output: startfile + ".tbi"
    conda: "envs/bcftools.yaml"
    threads: 1
    resources:
        mem_mb = 2048,
        time_min = 120
    shell: "bcftools index -t {input}"

rule fixheaders:
    input:
        vcf = startfile,
        tbi = rules.indexinitial.output,
    output:
        vcf = temp("{impute_dir}/temp/fixedheader/{cohort}/chr{chrom}.dose.vcf.gz"),
        tbi = temp("{impute_dir}/temp/fixedheader/{cohort}/chr{chrom}.dose.vcf.gz.tbi"),
    threads: 1
    resources:
        mem_mb = 2048,
        walltime = '24:00'
    conda: "envs/bcftools.yaml"
    shell:
        r"""
if $(zcat {input} | head -n 4000 | grep -q -e "##FILTER" -e "##INFO=<ID=IMPUTED"); then
  cp {input.vcf} {output.vcf}
  cp {input.tbi} {output.tbi}
else
  zcat {input.vcf} | sed '/contig/ a\
##FILTER=<ID=GENOTYPED,Description="Marker was genotyped AND imputed">\
##FILTER=<ID=GENOTYPED_ONLY,Description="Marker was genotyped but NOT imputed">' | \
bcftools view -Oz -o {output.vcf}
  bcftools index -t {output.vcf}
fi
"""

filter_out = "{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_filtered.vcf.gz"


if sampfilt:
    rule filters:
        input:
            vcf = rules.fixheaders.output.vcf if fixheaders else startfile,
            tbi = rules.fixheaders.output.tbi if fixheaders else startfile + '.tbi'
        output: temp(filter_out)
        params:
            filt = qualfilt,
            sf = sampfilt
        threads: 8
        resources:
            mem_mb = 256,
            walltime = '24:00'
        conda: "envs/bcftools.yaml"
        shell:
            r'''
if zcat {input.vcf} | head -n 4000 | grep -q "##INFO=<ID=IMPUTED"; then
  echo "Processing Minimac4 file"
  {params.sf} --force-samples -Oz --threads 8 {input.vcf} | \
  bcftools annotate -i "INFO/TYPED=1 || INFO/TYPED_ONLY=1 || {params.filt}" \
    -Oz -o {output} --set-id '%CHROM:%POS:%REF:%ALT' --threads 8
else
  echo "Processing Minimac3 file"
  {params.sf} --force-samples -Oz --threads 8 {input.vcf} | \
  bcftools annotate -i \
    "%FILTER='GENOTYPED' || %FILTER='GENOTYPED_ONLY' || {params.filt}" \
    -Oz -o {output} --set-id '%CHROM:%POS:%REF:%ALT' --threads 8
fi'''

else:
    rule filters:
        input:
            vcf = rules.fixheaders.output.vcf if fixheaders else startfile,
            tbi = rules.fixheaders.output.tbi if fixheaders else startfile + '.tbi'
        output: temp(filter_out)
        params:
            filt = qualfilt
        threads: 8
        resources:
            mem_mb = 256,
            walltime = '24:00'
        conda: "envs/bcftools.yaml"
        shell:
            r'''
if zcat {input.vcf} | head -n 4000 | grep -q "##INFO=<ID=IMPUTED"; then
  echo "Processing Minimac4 file"
  bcftools annotate -i "INFO/TYPED=1 || INFO/TYPED_ONLY=1 || {params.filt}" \
    -Oz -o {output} --set-id '%CHROM:%POS:%REF:%ALT' --threads 8 {input.vcf}
else
  echo "Processing Minimac3 file"
  bcftools annotate -i \
    "%FILTER='GENOTYPED' || %FILTER='GENOTYPED_ONLY' || {params.filt}" \
    -Oz -o {output} --set-id '%CHROM:%POS:%REF:%ALT' --threads 8 {input.vcf}
fi'''

# defaults for renaming:
renamed_cat = "{{impute_dir}}/data/by_chrom/{{cohort}}_chr{chrom}_filtered.vcf.gz"
renamed = "{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_filtered.vcf.gz"
renamed_merge = "{{impute_dir}}/data/by_chrom/{cohort}_chr{{chrom}}_filtered.vcf.gz"
automap_tf = False
rename_tf = False

#override defaults:
if 'rename' in config:
    if (config['rename'] is not None and
        'automap' in config['rename'] and
        config['rename']['automap']):
        print("Automatically renaming samples.")
        automap_tf = True
        automap = config['rename']['automap']
        renamed_cat = "{{impute_dir}}/data/by_chrom/{{cohort}}_chr{chrom}_filtered_fixedIDs.vcf.gz"
        renamed = "{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_filtered_fixedIDs.vcf.gz"
        renamed_merge = "{{impute_dir}}/data/by_chrom/{cohort}_chr{{chrom}}_filtered_fixedIDs.vcf.gz"
    elif config['rename'] and not type(config['rename']) is dict:
        print("Manualy renameing samples")
        renamefile = config['rename']
        renamed_cat = "{{impute_dir}}/data/by_chrom/{{cohort}}_chr{chrom}_filtered_renamed.vcf.gz"
        renamed = "{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_filtered_renamed.vcf.gz"
        renamed_merge = "{{impute_dir}}/data/by_chrom/{cohort}_chr{{chrom}}_filtered_renamed.vcf.gz"

rule rename:
    input:
        vcf = rules.filters.output,
        mapping = renamefile if rename_tf else "/dev/null"
    output:
        temp("{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_filtered_renamed.vcf.gz")
    conda: "envs/bcftools.yaml"
    threads: 2
    resources:
        mem_mb = 1024,
        time_min = 60
    shell:
        '''
bcftools reheader --samples {input.mapping} -o {output} | \
  bcftools view -o {output} -Oz
'''

rule fixHeader:
    input:
        vcf = rules.filters.output,
        mapping = automap if automap_tf else "/dev/null"
    output:
        mapping = "{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_vcfmap.tsv",
        reheader = temp("{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_vcfreheader.txt")
    conda: "envs/r.yaml"
    threads: 1
    resources:
        mem_mb = 8000,
        time_min = 120
    script: "workflow/scripts/fix_HRCvcf.R"

rule renameAuto:
    input:
        vcf = rules.filters.output,
        header = rules.fixHeader.output.reheader
    output:
        temp("{impute_dir}/data/by_chrom/{cohort}_chr{chrom}_filtered_fixedIDs.vcf.gz"),
    conda: "envs/bcftools.yaml"
    threads: 2
    resources:
        mem_mb = 1024,
        time_min = 60
    shell:
        '''
bcftools reheader --samples {input.header} {input.vcf} | \
  bcftools view -o {output} -Oz
'''

rule concat_chroms_samp:
    input: expand(renamed_cat, chrom=CHROM)
    output: "{impute_dir}/data/{cohort}_chrall_filtered.vcf.gz"
    threads: 8
    resources:
        mem_mb = 512,
        walltime = '24:00'
    conda: "envs/bcftools.yaml"
    shell: "bcftools concat -o {output} -Oz --threads 8 {input}"

rule index_samples_chrom:
    input: renamed
    output: renamed + ".tbi"
    conda: "envs/bcftools.yaml"
    threads: 1
    resources:
        mem_mb = 256,
        time_min = 120
    shell: "bcftools index -t {input}"

rule merge_samples_chrom:
    input:
        vcf = expand(renamed_merge, cohort=COHORT),
        tbi = expand(renamed_merge + ".tbi", cohort=COHORT)
    output: "{impute_dir}/data/by_chrom/all_chr{chrom}_filtered.vcf.gz"
    threads: 8
    resources:
        mem_mb = 2000,
        walltime = "36:00"
    conda: "envs/bcftools.yaml"
    shell: "bcftools merge -m none -o {output} -Oz --threads 8 {input.vcf}"

rule concat_chroms_all:
    input: expand("{{impute_dir}}/data/by_chrom/all_chr{chrom}_filtered.vcf.gz", chrom=CHROM)
    output: "{impute_dir}/data/all_chrall_filtered.vcf.gz"
    threads: 8
    resources:
        mem_mb = 256,
        walltime = "24:00"
    conda: "envs/bcftools.yaml"
    shell: "bcftools concat -o {output} -Oz --threads 8 {input}"

rule make_plink_all:
    input: rules.concat_chroms_all.output
    output: multiext("{impute_dir}/data/all_chrall_filtered", ".bed", ".bim", ".fam")
    params:
        out_plink = "{impute_dir}/data/all_chrall_filtered",
        ID = "--id-delim" if automap_tf else "--double-id"
    threads: 10
    resources:
        mem_mb = 3000,
        walltime = "96:00"
    conda: "envs/plink.yaml"
    shell:
        "plink --keep-allele-order --vcf {input} {params.ID} --memory 10000 --threads 10 --make-bed "
        "--out {params.out_plink}"

rule make_plink_samp:
    input: rules.concat_chroms_samp.output
    output: multiext("{impute_dir}/data/{cohort}_chrall_filtered", ".bed", ".bim", ".fam")
    params:
        out_plink = "{impute_dir}/data/{cohort}_chrall_filtered",
        ID = "--id-delim" if automap_tf else "--double-id "
    threads: 10
    resources:
        mem_mb = 1000,
        walltime = "2:00"
    conda: "envs/plink.yaml"
    shell:
        "plink --keep-allele-order --vcf {input} {params.ID} --memory 10000 --threads 10 --make-bed "
        "--out {params.out_plink}"

# If bgen outputs are requested
include: "rules/bgen.smk"
